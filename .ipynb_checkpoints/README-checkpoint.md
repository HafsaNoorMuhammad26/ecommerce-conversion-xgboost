# ğŸ›’ Ecommerce Conversion Prediction with XGBoost

This project predicts whether an online shopper will complete a purchase based on their session behavior using **XGBoost**.

---

## ğŸ“Œ Project Overview

Understanding online shopper behavior is key for improving e-commerce conversions.  
In this project, we:
- Perform **Exploratory Data Analysis (EDA)** to uncover purchase behavior patterns.
- Train an **XGBoost classifier** to predict purchase intent.
- Tune hyperparameters for better performance.
- Visualize results with confusion matrix, ROC curve, and feature importance.

---

## ğŸ“‚ Dataset

- **File**: `online_shoppers_intention.csv`
- **Source**: [UCI ML Repository â€“ Online Shoppers Purchasing Intention Dataset](https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset)
- **Target Variable**: `Revenue` (True = Purchase made, False = No purchase)

---

## ğŸ““ Notebook

- **`HafsaNoorMuhammad_OnlineShoppersPurchaseIntentions_P5.ipynb`**  
  Steps included:
  - Data loading
  - EDA and visualization
  - Data preprocessing
  - XGBoost model training
  - Hyperparameter tuning
  - Model evaluation

---

## ğŸš€ Quick Start

### Install Requirements
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost jupyter
````

### Run the Notebook

```bash
jupyter notebook HafsaNoorMuhammad_OnlineShoppersPurchaseIntentions_P5.ipynb
```

---

## ğŸ§  What is XGBoost?

**XGBoost** (Extreme Gradient Boosting) is a powerful machine learning library optimized for:

* **Speed** â€” parallel computation and efficient memory usage.
* **Accuracy** â€” built-in regularization to avoid overfitting.
* **Flexibility** â€” works for classification, regression, and ranking problems.

We chose XGBoost because:

* It handles **structured/tabular data** very well.
* It supports **feature importance ranking**.
* Itâ€™s highly efficient for large datasets.

---

## ğŸ¯ Hyperparameter Tuning

We tuned:

* `max_depth` â€” Tree depth.
* `learning_rate` â€” Step size shrinkage.
* `n_estimators` â€” Number of boosting rounds.
* `subsample` â€” Fraction of rows per tree.
* `colsample_bytree` â€” Fraction of features per tree.
* `gamma` â€” Minimum loss reduction for a split.

**Methods used**:

* **GridSearchCV** â€” Exhaustive parameter search.
* **RandomizedSearchCV** â€” Faster random parameter sampling.

---

## ğŸ“Š Model Evaluation & Visuals

### Confusion Matrix

![Confusion Matrix](images/confusion_matrix.png)

### ROC Curve

![ROC Curve](images/roc_curve.png)

### Feature Importance

![Feature Importance](images/feature_importance.png)

---

## ğŸ“ Project Structure

```
ecommerce-conversion-xgboost/
â”‚
â”œâ”€â”€ online_shoppers_intention.csv
â”œâ”€â”€ HafsaNoorMuhammad_OnlineShoppersPurchaseIntentions_P5.ipynb
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â””â”€â”€ feature_importance.png
â””â”€â”€ README.md
```

---

## ğŸ¤ Contributions

**Author**: Hafsa Noor Muhammad
* ğŸŒ [LinkedIn](https://www.linkedin.com/in/hafsa-noor-muhammad-67b96331a/)
* ğŸ“ [GitHub](https://github.com/HafsaNoorMuhammad26)
---

## ğŸ“š References

* [UCI Dataset](https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset)
* [XGBoost Documentation](https://xgboost.readthedocs.io/)
* [Scikit-learn Documentation](https://scikit-learn.org/)

```
